{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MGnify notebook: retrieve info from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ansi coor\n",
    "RED = '\\033[91m'\n",
    "GREEN = '\\033[92m'\n",
    "YELLOW = '\\033[93m'\n",
    "BLUE = '\\033[94m'\n",
    "MAGENTA = '\\033[95m'\n",
    "CYAN = '\\033[96m'\n",
    "RESET = '\\033[0m' "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_studies_and_analyses_summary(biome_name, experiment_type):\n",
    "    # set the urls\n",
    "    urls = {\"studies\": \"https://www.ebi.ac.uk/metagenomics/api/v1/studies\", \"analyses\": \"https://www.ebi.ac.uk/metagenomics/api/v1/analyses\"}\n",
    "    # common parts\n",
    "    common_params = {\"biome_name\": biome_name}\n",
    "    all_data = {\"studies\": [], \"analyses\": []}\n",
    "\n",
    "    # connection request\n",
    "    for key, url in urls.items():\n",
    "        params = common_params.copy()\n",
    "        if key == \"analyses\":\n",
    "            params.update({\n",
    "                \"lineage\": biome_name,\n",
    "                \"experiment_type\": experiment_type\n",
    "            })\n",
    "        page = 1\n",
    "        while True:\n",
    "            try:\n",
    "                print(f\"Retrieving data for page {page}...\")\n",
    "                params[\"page\"] = page\n",
    "                response = requests.get(url, params=params)\n",
    "                response.raise_for_status()  # errors codes HTTP\n",
    "                \n",
    "                data = response.json()[\"data\"]\n",
    "                page_info = response.json()[\"meta\"][\"pagination\"]\n",
    "                all_data[key].extend(data)\n",
    "                print(f\"Page {page} retrieved successfully. Total pages: {page_info['pages']}\")\n",
    "\n",
    "                if page >= page_info[\"pages\"]:\n",
    "                    break\n",
    "                page += 1\n",
    "            except requests.exceptions.HTTPError as http_err:\n",
    "                print(f\"HTTP error occurred: {http_err} - Status code: {response.status_code}\")\n",
    "                break\n",
    "            except Exception as err:\n",
    "                print(f\"An error occurred: {err}\")\n",
    "                break\n",
    "    \n",
    "    # building dataframes\n",
    "    studies_columns = ['study_id', 'study_name', 'n_samples', 'bioproject', 'centre_name', 'biomes']\n",
    "    studies_data = []\n",
    "    for item in all_data['studies']:\n",
    "        studies_data.append({\n",
    "            'study_id': item['id'],\n",
    "            'study_name': item['attributes'].get('study-name', ''),\n",
    "            'n_samples': item['attributes'].get('samples-count', 0),\n",
    "            'bioproject': item['attributes'].get('bioproject', ''),\n",
    "            'centre_name': item['attributes'].get('centre-name', ''),\n",
    "            'biomes': \", \".join([biome['id'] for biome in item['relationships']['biomes']['data']])\n",
    "            })\n",
    "    df_studies = pd.DataFrame(studies_data, columns=studies_columns)\n",
    "\n",
    "    analyses_columns = ['analysis_id', 'experiment_type', 'pipeline_version', 'instrument_platform', 'study_id', 'sample_id', 'assembly_run_id']\n",
    "    analyses_data = []\n",
    "    for item in all_data['analyses']:\n",
    "        analyses_data.append({\n",
    "            'analysis_id': item['id'],\n",
    "            'experiment_type': item['attributes'].get('experiment-type', ''),\n",
    "            'pipeline_version': item['attributes'].get('pipeline-version', ''),\n",
    "            'instrument_platform': item['attributes'].get('instrument-model', ''),\n",
    "            'study_id': item['relationships']['study']['data'].get('id', '') if item['relationships'].get('study') else '',\n",
    "            'sample_id': item['relationships']['sample']['data'].get('id', '') if item['relationships'].get('sample') else '',\n",
    "            'assembly_run_id': item['relationships'].get('assembly', {}).get('data', {}).get('id', '') if item['attributes'].get('experiment-type') == 'assembly' else item['relationships'].get('run', {}).get('data', {}).get('id', '')\n",
    "            })\n",
    "    df_analyses = pd.DataFrame(analyses_data, columns=analyses_columns)\n",
    "\n",
    "    # merging dataframe and return it\n",
    "    df_summary = pd.merge(df_analyses, df_studies, on='study_id', how='left')\n",
    "    \n",
    "    return df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_biomes_and_save(output_dir):\n",
    "    \"\"\"\n",
    "    Fetches the list of biomes from the MGnify API and saves it to a text file in the specified output directory.\n",
    "    The function makes a GET request to the MGnify API's biomes endpoint, extracts the biome IDs from the response,\n",
    "    and writes them to a file named 'mgnify_biomes_list.txt' within the given output directory.\n",
    "\n",
    "    Args:\n",
    "        output_dir (str): The directory path where the biomes list file will be saved. The directory must exist.\n",
    "\n",
    "    Note:\n",
    "        This function requires the 'requests' library for making HTTP requests and 'os' library for file path operations.\n",
    "    \"\"\"\n",
    "    url = \"https://www.ebi.ac.uk/metagenomics/api/v1/biomes\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        biomes_data = response.json()\n",
    "        biomes_list = [biome['id'] for biome in biomes_data['data']]\n",
    "        \n",
    "        # Ensure the output directory exists\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        # Write the biome IDs to a file\n",
    "        with open(os.path.join(output_dir, \"mgnify_biomes_list.txt\"), 'w') as file:\n",
    "            for biome_name in biomes_list:\n",
    "                file.write(f\"{biome_name}\\n\")\n",
    "                \n",
    "        print(\"Biomes list saved successfully.\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Failed to retrieve biomes. Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_studies_and_analyses_summary(biome_name, experiment_type, output_dir = '../outputs'):\n",
    "    \"\"\"\n",
    "    Fetches and summarizes studies and analyses data from the MGnify API based on the specified biome name\n",
    "    and experiment type. It saves the raw data as JSON and returns a merged DataFrame summary.\n",
    "\n",
    "    This function queries the MGnify API for studies and analyses related to a specific biome and experiment type.\n",
    "    The results are saved in separate JSON files within the specified output directory and then processed to\n",
    "    create and return a comprehensive DataFrame summary.\n",
    "\n",
    "    Args:\n",
    "        biome_name (str): The name of the biome to filter studies and analyses.\n",
    "        experiment_type (str): The type of experiment to filter analyses.\n",
    "        output_dir (str, optional): The directory path where the JSON files will be saved. Defaults to '../outputs'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame summarizing the studies and analyses, including key details like study ID,\n",
    "                      study name, number of samples, and related analysis information.\n",
    "    \"\"\"\n",
    "\n",
    "    # API URLs for fetching studies and analyses data\n",
    "    urls = {\"studies\": \"https://www.ebi.ac.uk/metagenomics/api/v1/studies\", \"analyses\": \"https://www.ebi.ac.uk/metagenomics/api/v1/analyses\"}\n",
    "\n",
    "    # common parameters for API requests\n",
    "    common_params = {\"biome_name\": biome_name}\n",
    "    all_data = {\"studies\": [], \"analyses\": []}\n",
    "\n",
    "    # connection request\n",
    "    for key, url in urls.items():\n",
    "        if key == \"studies\" and all_data[\"studies\"]:\n",
    "            continue\n",
    "\n",
    "        params = common_params.copy()\n",
    "        if key == \"analyses\":\n",
    "            params.update({\n",
    "                \"lineage\": biome_name,\n",
    "                \"experiment_type\": experiment_type\n",
    "            })\n",
    "\n",
    "        page = 1\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                print(f\"Retrieving data for page {page}...\")\n",
    "                params[\"page\"] = page\n",
    "                response = requests.get(url, params=params)\n",
    "                response.raise_for_status()  # errors codes HTTP\n",
    "                \n",
    "                data = response.json()[\"data\"]\n",
    "                page_info = response.json()[\"meta\"][\"pagination\"]\n",
    "                all_data[key].extend(data)\n",
    "                print(f\"Page {page} retrieved successfully. Total pages: {page_info['pages']}\")\n",
    "\n",
    "                if page >= page_info[\"pages\"]:\n",
    "                    break\n",
    "                page += 1\n",
    "            except requests.exceptions.HTTPError as http_err:\n",
    "                print(f\"HTTP error occurred: {http_err} - Status code: {response.status_code}\")\n",
    "                break\n",
    "            except Exception as err:\n",
    "                print(f\"An error occurred: {err}\")\n",
    "                break\n",
    "        \n",
    "        # save json files\n",
    "        if key == \"studies\":\n",
    "            output_file_path = os.path.join(output_dir, \"mgnify_studies.json\")\n",
    "        else:\n",
    "            output_file_path = os.path.join(output_dir, f\"mgnify_analyses_{experiment_type}.json\")\n",
    "        \n",
    "        with open(output_file_path, \"w\") as outfile:\n",
    "            json.dump(all_data[key], outfile)\n",
    "        print(f\"{key.capitalize()} data for {experiment_type} saved to {output_file_path}\")\n",
    "\n",
    "\n",
    "    # building dataframes\n",
    "    studies_columns = ['study_id', 'study_name', 'n_samples', 'bioproject', 'centre_name', 'biomes']\n",
    "    studies_data = []\n",
    "    for item in all_data['studies']:\n",
    "        studies_data.append({\n",
    "            'study_id': item['id'],\n",
    "            'study_name': item['attributes'].get('study-name', ''),\n",
    "            'n_samples': item['attributes'].get('samples-count', 0),\n",
    "            'bioproject': item['attributes'].get('bioproject', ''),\n",
    "            'centre_name': item['attributes'].get('centre-name', ''),\n",
    "            'biomes': \", \".join([biome['id'] for biome in item['relationships']['biomes']['data']])\n",
    "            })\n",
    "    df_studies = pd.DataFrame(studies_data, columns=studies_columns)\n",
    "\n",
    "    analyses_columns = ['analysis_id', 'experiment_type', 'pipeline_version', 'instrument_platform', 'study_id', 'sample_id', 'assembly_run_id']\n",
    "    analyses_data = []\n",
    "    for item in all_data['analyses']:\n",
    "        analyses_data.append({\n",
    "            'analysis_id': item['id'],\n",
    "            'experiment_type': item['attributes'].get('experiment-type', ''),\n",
    "            'pipeline_version': item['attributes'].get('pipeline-version', ''),\n",
    "            'instrument_platform': item['attributes'].get('instrument-model', ''),\n",
    "            'study_id': item['relationships']['study']['data'].get('id', '') if item['relationships'].get('study') else '',\n",
    "            'sample_id': item['relationships']['sample']['data'].get('id', '') if item['relationships'].get('sample') else '',\n",
    "            'assembly_run_id': item['relationships'].get('assembly', {}).get('data', {}).get('id', '') if item['attributes'].get('experiment-type') == 'assembly' else item['relationships'].get('run', {}).get('data', {}).get('id', '')\n",
    "            })\n",
    "    df_analyses = pd.DataFrame(analyses_data, columns=analyses_columns)\n",
    "\n",
    "    # merging dataframe and return it\n",
    "    df_summary = pd.merge(df_analyses, df_studies, on='study_id', how='left')\n",
    "    \n",
    "    return df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Explores the given dataset by printing out statistics and information related to its composition.\n",
    "    This includes the total number of unique studies, the distribution of unique assembly run IDs per study,\n",
    "    the presence of missing values across variables, and the median number of samples per biome.\n",
    "\n",
    "    Args:\n",
    "        dataset (pd.DataFrame): The dataset to be explored. It must contain the columns 'study_id',\n",
    "                                'assembly_run_id', 'biomes', and 'n_samples' among others.\n",
    "\n",
    "    Note:\n",
    "        The function assumes 'combined_df' is the dataset passed through the 'dataset' argument for some print statements.\n",
    "        Replace 'combined_df' with 'dataset' in the actual implementation if 'combined_df' is a typo.\n",
    "    \"\"\"\n",
    "    print(\"\\nTotal number of unique studies\")\n",
    "    display(dataset['study_id'].nunique())\n",
    "    print(GREEN + \"_._\" * 25 + RESET)\n",
    "\n",
    "    print(\"\\nNumber of unique assembly_run_id per study_id\")\n",
    "    print(dataset.groupby('study_id')['assembly_run_id'].nunique())\n",
    "    print(GREEN + \"_._\" * 25 + RESET)\n",
    "\n",
    "    # missing data\n",
    "    print(\"\\nMissing values per variable\")\n",
    "    print(dataset.isnull().sum())\n",
    "    any_missing_data = dataset.isnull().values.any()\n",
    "    print(f\"Are there any missing data in the dataframe? {'yes' if any_missing_data else 'no'}\")\n",
    "    print(GREEN + \"_._\" * 25 + RESET)\n",
    "\n",
    "    print(\"\\nNumber of samples per biome (median)\")\n",
    "    print(dataset.groupby('biomes')['n_samples'].median().reset_index())\n",
    "    print(GREEN + \"_._\" * 25 + RESET)\n",
    "\n",
    "    experiment_type_counts = dataset[\"experiment_type\"].value_counts()\n",
    "    biomes_counts = dataset[\"biomes\"].value_counts()\n",
    "\n",
    "    print(\"\\nDistribuzione di experiment_type:\")\n",
    "    print(experiment_type_counts)\n",
    "\n",
    "    print(\"\\nDistribuzione di biomes:\")\n",
    "    print(biomes_counts)\n",
    "    print(GREEN + \"_._\" * 25 + RESET)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(dataframe):\n",
    "    \"\"\"\n",
    "    Performs feature engineering on the provided dataframe. It includes mapping pipeline versions\n",
    "    to a simplified numerical scale, extracting initials from the 'assembly_run_id', and concatenating\n",
    "    multiple identifiers into a single 'concatenated_ids' column.\n",
    "    \n",
    "    The function does the following transformations:\n",
    "    - Maps 'pipeline_version' to 'pipeline_mapped' using a predefined version mapping for simplification.\n",
    "    - Extracts the first three characters from 'assembly_run_id' and stores them in 'initials_run'.\n",
    "    - Concatenates 'study_id', 'sample_id', 'assembly_run_id', and 'bioproject' into a new 'concatenated_ids' column.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): The input dataframe to process. It must contain the columns 'pipeline_version',\n",
    "                                  'assembly_run_id', 'study_id', 'sample_id', and 'bioproject'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe with added features based on the original data.\n",
    "    \"\"\"\n",
    "\n",
    "    version_mapping = {1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 4.1: 5, 5.0: 6}\n",
    "    dataframe['pipeline_mapped'] = dataframe['pipeline_version'].map(version_mapping)\n",
    "\n",
    "    # extract the first three characters from 'assembly_run_id'\n",
    "    dataframe['initials_run'] = dataframe['assembly_run_id'].str[:3]\n",
    "\n",
    "    dataframe['concatenated_ids'] = dataframe['study_id'] + '_' + dataframe['sample_id'] + '_' + dataframe['assembly_run_id'] + '_' + dataframe['bioproject']\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_duplicates(dataframe):\n",
    "    \"\"\"\n",
    "    Removes duplicate rows from the dataframe based on the 'concatenated_ids' column.\n",
    "    Among duplicates, it retains only the row with the highest value in the 'pipeline_mapped' column.\n",
    "    \n",
    "    This function first counts the occurrences of each unique 'concatenated_ids' value to identify duplicates.\n",
    "    For each set of duplicates, it sorts them by 'pipeline_mapped' in descending order and keeps the top one,\n",
    "    effectively removing duplicates with lower 'pipeline_mapped' values. Rows without duplicates are preserved as is.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): The dataframe to process. It must contain the columns 'concatenated_ids' and 'pipeline_mapped'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe with duplicates removed based on the above criteria.\n",
    "    \"\"\"\n",
    "    # Count occurrences of each unique ID in 'concatenated_ids'\n",
    "    counts = dataframe['concatenated_ids'].value_counts()\n",
    "    duplicates = (counts > 1).sum()\n",
    "\n",
    "    # Report the number of duplicate IDs found\n",
    "    print(f\"Number of duplicates in the dataset: {duplicates}\")\n",
    "\n",
    "    # Initialize an empty DataFrame to store the filtered results\n",
    "    filtered_df = pd.DataFrame()\n",
    "\n",
    "    # Process each ID with more than one occurrence to identify and keep only the desired row\n",
    "    for id, count in counts[counts > 1].items():\n",
    "        # Select rows matching the current duplicate ID\n",
    "        dup_rows = dataframe[dataframe['concatenated_ids'] == id]\n",
    "        # Sort these rows by 'pipeline_mapped' in descending order and select the top one\n",
    "        highest_pipeline_mapped_row = dup_rows.sort_values(by='pipeline_mapped', ascending=False).head(1)\n",
    "        # Append the selected row to the filtered DataFrame\n",
    "        filtered_df = pd.concat([filtered_df, highest_pipeline_mapped_row], ignore_index=True)\n",
    "    \n",
    "    # Identify and include rows that are not duplicates\n",
    "    non_duplicate_ids = counts[counts == 1].index\n",
    "    non_duplicate_rows = dataframe[dataframe['concatenated_ids'].isin(non_duplicate_ids)]\n",
    "    filtered_df = pd.concat([filtered_df, non_duplicate_rows], ignore_index=True)\n",
    "\n",
    "    # Return the DataFrame with duplicates removed\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING STEP 1: fetch_biomes_and_save\n",
      "Biomes list saved.\n",
      "STARTING STEP 2: get_studies_and_analyses_summary\n",
      "Processing experiment type: metagenomic\n",
      "Retrieving data for page 1...\n",
      "Page 1 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 2...\n",
      "Page 2 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 3...\n",
      "Page 3 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 4...\n",
      "Page 4 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 5...\n",
      "Page 5 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 6...\n",
      "Page 6 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 7...\n",
      "Page 7 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 8...\n",
      "Page 8 retrieved successfully. Total pages: 8\n",
      "Studies data for metagenomic saved to ../outputs/mgnify_studies.json\n",
      "Retrieving data for page 1...\n",
      "Page 1 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 2...\n",
      "Page 2 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 3...\n",
      "Page 3 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 4...\n",
      "Page 4 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 5...\n",
      "Page 5 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 6...\n",
      "Page 6 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 7...\n",
      "Page 7 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 8...\n",
      "Page 8 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 9...\n",
      "Page 9 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 10...\n",
      "Page 10 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 11...\n",
      "Page 11 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 12...\n",
      "Page 12 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 13...\n",
      "Page 13 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 14...\n",
      "Page 14 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 15...\n",
      "Page 15 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 16...\n",
      "Page 16 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 17...\n",
      "Page 17 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 18...\n",
      "Page 18 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 19...\n",
      "Page 19 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 20...\n",
      "Page 20 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 21...\n",
      "Page 21 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 22...\n",
      "Page 22 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 23...\n",
      "Page 23 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 24...\n",
      "Page 24 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 25...\n",
      "Page 25 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 26...\n",
      "Page 26 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 27...\n",
      "Page 27 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 28...\n",
      "Page 28 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 29...\n",
      "Page 29 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 30...\n",
      "Page 30 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 31...\n",
      "Page 31 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 32...\n",
      "Page 32 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 33...\n",
      "Page 33 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 34...\n",
      "Page 34 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 35...\n",
      "Page 35 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 36...\n",
      "Page 36 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 37...\n",
      "Page 37 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 38...\n",
      "Page 38 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 39...\n",
      "Page 39 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 40...\n",
      "Page 40 retrieved successfully. Total pages: 40\n",
      "Analyses data for metagenomic saved to ../outputs/mgnify_analyses_metagenomic.json\n",
      "Processing experiment type: metatranscriptomic\n",
      "Retrieving data for page 1...\n",
      "Page 1 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 2...\n",
      "Page 2 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 3...\n",
      "Page 3 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 4...\n",
      "Page 4 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 5...\n",
      "Page 5 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 6...\n",
      "Page 6 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 7...\n",
      "Page 7 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 8...\n",
      "Page 8 retrieved successfully. Total pages: 8\n",
      "Studies data for metatranscriptomic saved to ../outputs/mgnify_studies.json\n",
      "Retrieving data for page 1...\n",
      "Page 1 retrieved successfully. Total pages: 4\n",
      "Retrieving data for page 2...\n",
      "Page 2 retrieved successfully. Total pages: 4\n",
      "Retrieving data for page 3...\n",
      "Page 3 retrieved successfully. Total pages: 4\n",
      "Retrieving data for page 4...\n",
      "Page 4 retrieved successfully. Total pages: 4\n",
      "Analyses data for metatranscriptomic saved to ../outputs/mgnify_analyses_metatranscriptomic.json\n",
      "Processing experiment type: assembly\n",
      "Retrieving data for page 1...\n",
      "Page 1 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 2...\n",
      "Page 2 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 3...\n",
      "Page 3 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 4...\n",
      "Page 4 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 5...\n",
      "Page 5 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 6...\n",
      "Page 6 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 7...\n",
      "Page 7 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 8...\n",
      "Page 8 retrieved successfully. Total pages: 8\n",
      "Studies data for assembly saved to ../outputs/mgnify_studies.json\n",
      "Retrieving data for page 1...\n",
      "Page 1 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 2...\n",
      "Page 2 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 3...\n",
      "Page 3 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 4...\n",
      "Page 4 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 5...\n",
      "Page 5 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 6...\n",
      "Page 6 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 7...\n",
      "Page 7 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 8...\n",
      "Page 8 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 9...\n",
      "Page 9 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 10...\n",
      "Page 10 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 11...\n",
      "Page 11 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 12...\n",
      "Page 12 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 13...\n",
      "Page 13 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 14...\n",
      "Page 14 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 15...\n",
      "Page 15 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 16...\n",
      "Page 16 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 17...\n",
      "Page 17 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 18...\n",
      "Page 18 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 19...\n",
      "Page 19 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 20...\n",
      "Page 20 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 21...\n",
      "Page 21 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 22...\n",
      "Page 22 retrieved successfully. Total pages: 22\n",
      "Analyses data for assembly saved to ../outputs/mgnify_analyses_assembly.json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # setting the variables \n",
    "    biome = \"root:Engineered:Wastewater\"\n",
    "    biome_lower = biome.replace(\":\", \"_\").lower()\n",
    "    experiments = (\"metagenomic\",\"metatranscriptomic\",\"assembly\")\n",
    "    output_path = '../outputs/'\n",
    "    df_summary_dict = {}\n",
    "\n",
    "    print('STARTING STEP 1: fetch_biomes_and_save')\n",
    "    fetch_biomes_and_save(output_dir= output_path)\n",
    "\n",
    "    print('STARTING STEP 2: get_studies_and_analyses_summary')\n",
    "    for exp in experiments:\n",
    "        print(f\"Processing experiment type: {exp}\")\n",
    "        df_summary = get_studies_and_analyses_summary(biome_name=biome, experiment_type=exp)\n",
    "        df_summary_dict[exp] = df_summary  # Aggiungi il DataFrame al dizionario\n",
    "\n",
    "        # save the CSV file\n",
    "        df_summary.to_csv(os.path.join(output_path, f\"{biome_lower}_{exp}_summary.csv\"), index=False)\n",
    "        combined_df = pd.concat(df_summary_dict.values(), axis=0)\n",
    "        combined_df.to_csv(os.path.join(output_path, 'combined_dataframe.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mSTARTING STEP 3: explore_dataset\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "analysis_id             object\n",
       "experiment_type         object\n",
       "pipeline_version       float64\n",
       "instrument_platform     object\n",
       "study_id                object\n",
       "sample_id               object\n",
       "assembly_run_id         object\n",
       "study_name              object\n",
       "n_samples                int64\n",
       "bioproject              object\n",
       "centre_name             object\n",
       "biomes                  object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of unique studies\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m_.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__._\u001b[0m\n",
      "\n",
      "Number of unique assembly_run_id per study_id\n",
      "study_id\n",
      "MGYS00000423      1\n",
      "MGYS00000425      1\n",
      "MGYS00000555      1\n",
      "MGYS00000597     16\n",
      "MGYS00000606      1\n",
      "               ... \n",
      "MGYS00005614      8\n",
      "MGYS00005769     11\n",
      "MGYS00005802      6\n",
      "MGYS00005846    110\n",
      "MGYS00006570    152\n",
      "Name: assembly_run_id, Length: 117, dtype: int64\n",
      "\u001b[92m_.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__._\u001b[0m\n",
      "\n",
      "Missing values per variable\n",
      "analysis_id            0\n",
      "experiment_type        0\n",
      "pipeline_version       0\n",
      "instrument_platform    0\n",
      "study_id               0\n",
      "sample_id              0\n",
      "assembly_run_id        0\n",
      "study_name             0\n",
      "n_samples              0\n",
      "bioproject             0\n",
      "centre_name            0\n",
      "biomes                 0\n",
      "dtype: int64\n",
      "Are there any missing data in the dataframe? no\n",
      "\u001b[92m_.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__._\u001b[0m\n",
      "\n",
      "Number of samples per biome (median)\n",
      "                                              biomes  n_samples\n",
      "0                         root:Engineered:Wastewater       81.0\n",
      "1        root:Engineered:Wastewater:Activated Sludge       12.0\n",
      "2  root:Engineered:Wastewater:Activated Sludge, r...       70.0\n",
      "3   root:Engineered:Wastewater:Industrial wastewater       30.0\n",
      "4  root:Engineered:Wastewater:Industrial wastewat...        1.0\n",
      "5  root:Engineered:Wastewater:Industrial wastewat...       14.0\n",
      "6  root:Engineered:Wastewater:Nutrient removal:Bi...        6.0\n",
      "7  root:Engineered:Wastewater:Nutrient removal:Di...        6.0\n",
      "8  root:Engineered:Wastewater:Nutrient removal:Ni...        1.0\n",
      "9        root:Engineered:Wastewater:Water and sludge      179.0\n",
      "\u001b[92m_.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__._\u001b[0m\n",
      "\n",
      "Distribuzione di experiment_type:\n",
      "experiment_type\n",
      "metagenomic           985\n",
      "assembly              530\n",
      "metatranscriptomic     99\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribuzione di biomes:\n",
      "biomes\n",
      "root:Engineered:Wastewater:Water and sludge                                                      708\n",
      "root:Engineered:Wastewater                                                                       497\n",
      "root:Engineered:Wastewater:Activated Sludge                                                      225\n",
      "root:Engineered:Wastewater:Activated Sludge, root:Engineered:Wastewater:Industrial wastewater     70\n",
      "root:Engineered:Wastewater:Industrial wastewater                                                  67\n",
      "root:Engineered:Wastewater:Industrial wastewater:Petrochemical                                    24\n",
      "root:Engineered:Wastewater:Nutrient removal:Dissolved organics (anaerobic)                        12\n",
      "root:Engineered:Wastewater:Nutrient removal:Biological phosphorus removal:Activated sludge         8\n",
      "root:Engineered:Wastewater:Industrial wastewater:Agricultural wastewater                           2\n",
      "root:Engineered:Wastewater:Nutrient removal:Nitrogen removal                                       1\n",
      "Name: count, dtype: int64\n",
      "\u001b[92m_.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__.__._\u001b[0m\n",
      "\u001b[93mSTARTING STEP 4: feature_engineering\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "concatenated_ids\n",
       "MGYS00001976_ERS1874632_ERZ478770_PRJEB22150     2\n",
       "MGYS00001312_ERS1426853_ERR1713406_PRJEB13831    2\n",
       "MGYS00001312_ERS1426819_ERR1713372_PRJEB13831    2\n",
       "MGYS00001312_ERS1426803_ERR1713356_PRJEB13831    2\n",
       "MGYS00001312_ERS1426793_ERR1713346_PRJEB13831    2\n",
       "                                                ..\n",
       "MGYS00001312_ERS1443948_ERR1725972_PRJEB13831    1\n",
       "MGYS00001312_ERS1443952_ERR1725976_PRJEB13831    1\n",
       "MGYS00001312_ERS1443923_ERR1725947_PRJEB13831    1\n",
       "MGYS00001312_ERS1444006_ERR1726030_PRJEB13831    1\n",
       "MGYS00000777_ERS1107853_ERR1352918_PRJEB13232    1\n",
       "Name: count, Length: 1515, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mSTARTING STEP 5: removing_duplicates\u001b[0m\n",
      "Number of duplicates in the dataset: 99\n",
      "initials_run\n",
      "ERR    963\n",
      "ERZ    524\n",
      "SRR     20\n",
      "DRR      8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # setting the variables \n",
    "    biome = \"root:Engineered:Wastewater\"\n",
    "    biome_lower = biome.replace(\":\", \"_\").lower()\n",
    "    experiments = (\"metagenomic\",\"metatranscriptomic\",\"assembly\")\n",
    "    output_path = '../outputs/'\n",
    "    df_summary_dict = {}\n",
    "\n",
    "    combined_df = pd.read_csv(os.path.join(output_path, 'combined_dataframe.csv'))\n",
    "    print('\\033[93m' + 'STARTING STEP 3: explore_dataset' + '\\033[0m')\n",
    "    display(combined_df.dtypes)\n",
    "    explore_dataset(combined_df)\n",
    "    print('\\033[93m' + 'STARTING STEP 4: feature_engineering' + '\\033[0m')\n",
    "\n",
    "    combined_df_updated = feature_engineering(combined_df)\n",
    "    display(combined_df_updated['concatenated_ids'].value_counts())\n",
    "\n",
    "    print('\\033[93m' + 'STARTING STEP 5: removing_duplicates' + '\\033[0m')\n",
    "    new_dataframe = removing_duplicates(combined_df_updated)\n",
    "    print(new_dataframe[\"initials_run\"].value_counts())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(os.path.join(output_path, 'combined_dataframe.csv'), index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['metagenomic', 'metatranscriptomic', 'assembly'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.experiment_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n",
      "162\n",
      "197\n"
     ]
    }
   ],
   "source": [
    "### do we have different pipeline versions considering different IDs?\n",
    "\n",
    "analysis_versions = combined_df.groupby('analysis_id')['pipeline_version'].nunique()\n",
    "study_versions = combined_df.groupby('study_id')['pipeline_version'].nunique()\n",
    "sample_versions = combined_df.groupby('sample_id')['pipeline_version'].nunique()\n",
    "run_versions = combined_df.groupby('assembly_run_id')['pipeline_version'].nunique()\n",
    "\n",
    "multiple_versions_ana = analysis_versions[analysis_versions > 1]\n",
    "multiple_versions_stu = study_versions[study_versions > 1]\n",
    "multiple_versions_sam = sample_versions[sample_versions > 1]\n",
    "multiple_versions_run = run_versions[run_versions > 1]\n",
    "\n",
    "print(len(multiple_versions_ana))\n",
    "print(len(multiple_versions_stu))\n",
    "print(len(multiple_versions_sam))\n",
    "print(len(multiple_versions_run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>pipeline_version</th>\n",
       "      <th>instrument_platform</th>\n",
       "      <th>study_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>assembly_run_id</th>\n",
       "      <th>study_name</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>bioproject</th>\n",
       "      <th>centre_name</th>\n",
       "      <th>biomes</th>\n",
       "      <th>pipeline_mapped</th>\n",
       "      <th>initials_run</th>\n",
       "      <th>concatenated_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>MGYA00216627</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 3000</td>\n",
       "      <td>MGYS00001312</td>\n",
       "      <td>ERS1426778</td>\n",
       "      <td>ERR1713331</td>\n",
       "      <td>Global surveillance of infectious diseases and...</td>\n",
       "      <td>179</td>\n",
       "      <td>PRJEB13831</td>\n",
       "      <td>DTU-GE</td>\n",
       "      <td>root:Engineered:Wastewater:Water and sludge</td>\n",
       "      <td>5</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00001312_ERS1426778_ERR1713331_PRJEB13831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>MGYA00085654</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Illumina HiSeq 3000</td>\n",
       "      <td>MGYS00001312</td>\n",
       "      <td>ERS1426778</td>\n",
       "      <td>ERR1713331</td>\n",
       "      <td>Global surveillance of infectious diseases and...</td>\n",
       "      <td>179</td>\n",
       "      <td>PRJEB13831</td>\n",
       "      <td>DTU-GE</td>\n",
       "      <td>root:Engineered:Wastewater:Water and sludge</td>\n",
       "      <td>3</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00001312_ERS1426778_ERR1713331_PRJEB13831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      analysis_id experiment_type  pipeline_version  instrument_platform  \\\n",
       "357  MGYA00216627     metagenomic               4.1  Illumina HiSeq 3000   \n",
       "533  MGYA00085654     metagenomic               3.0  Illumina HiSeq 3000   \n",
       "\n",
       "         study_id   sample_id assembly_run_id  \\\n",
       "357  MGYS00001312  ERS1426778      ERR1713331   \n",
       "533  MGYS00001312  ERS1426778      ERR1713331   \n",
       "\n",
       "                                            study_name  n_samples  bioproject  \\\n",
       "357  Global surveillance of infectious diseases and...        179  PRJEB13831   \n",
       "533  Global surveillance of infectious diseases and...        179  PRJEB13831   \n",
       "\n",
       "    centre_name                                       biomes  pipeline_mapped  \\\n",
       "357      DTU-GE  root:Engineered:Wastewater:Water and sludge                5   \n",
       "533      DTU-GE  root:Engineered:Wastewater:Water and sludge                3   \n",
       "\n",
       "    initials_run                               concatenated_ids  \n",
       "357          ERR  MGYS00001312_ERS1426778_ERR1713331_PRJEB13831  \n",
       "533          ERR  MGYS00001312_ERS1426778_ERR1713331_PRJEB13831  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[combined_df['assembly_run_id'] == 'ERR1713331']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>pipeline_version</th>\n",
       "      <th>instrument_platform</th>\n",
       "      <th>study_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>assembly_run_id</th>\n",
       "      <th>study_name</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>bioproject</th>\n",
       "      <th>centre_name</th>\n",
       "      <th>biomes</th>\n",
       "      <th>pipeline_mapped</th>\n",
       "      <th>initials_run</th>\n",
       "      <th>concatenated_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MGYA00166416</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488844</td>\n",
       "      <td>ERR2586218</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "      <td>5</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00002383_ERS2488844_ERR2586218_PRJEB26809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MGYA00166417</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488846</td>\n",
       "      <td>ERR2586220</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "      <td>5</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00002383_ERS2488846_ERR2586220_PRJEB26809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MGYA00166418</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488842</td>\n",
       "      <td>ERR2586216</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "      <td>5</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00002383_ERS2488842_ERR2586216_PRJEB26809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    analysis_id experiment_type  pipeline_version  instrument_platform  \\\n",
       "0  MGYA00166416     metagenomic               4.1  Illumina HiSeq 2500   \n",
       "1  MGYA00166417     metagenomic               4.1  Illumina HiSeq 2500   \n",
       "2  MGYA00166418     metagenomic               4.1  Illumina HiSeq 2500   \n",
       "\n",
       "       study_id   sample_id assembly_run_id  \\\n",
       "0  MGYS00002383  ERS2488844      ERR2586218   \n",
       "1  MGYS00002383  ERS2488846      ERR2586220   \n",
       "2  MGYS00002383  ERS2488842      ERR2586216   \n",
       "\n",
       "                                          study_name  n_samples  bioproject  \\\n",
       "0  Antibiotic manufacturing effluent enriches res...          6  PRJEB26809   \n",
       "1  Antibiotic manufacturing effluent enriches res...          6  PRJEB26809   \n",
       "2  Antibiotic manufacturing effluent enriches res...          6  PRJEB26809   \n",
       "\n",
       "                centre_name                                       biomes  \\\n",
       "0  UNIVERSITY OF GOTHENBURG  root:Engineered:Wastewater:Activated Sludge   \n",
       "1  UNIVERSITY OF GOTHENBURG  root:Engineered:Wastewater:Activated Sludge   \n",
       "2  UNIVERSITY OF GOTHENBURG  root:Engineered:Wastewater:Activated Sludge   \n",
       "\n",
       "   pipeline_mapped initials_run                               concatenated_ids  \n",
       "0                5          ERR  MGYS00002383_ERS2488844_ERR2586218_PRJEB26809  \n",
       "1                5          ERR  MGYS00002383_ERS2488846_ERR2586220_PRJEB26809  \n",
       "2                5          ERR  MGYS00002383_ERS2488842_ERR2586216_PRJEB26809  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_updated.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "concatenated_ids\n",
       "MGYS00001976_ERS1874632_ERZ478770_PRJEB22150     2\n",
       "MGYS00001312_ERS1426853_ERR1713406_PRJEB13831    2\n",
       "MGYS00001312_ERS1426819_ERR1713372_PRJEB13831    2\n",
       "MGYS00001312_ERS1426803_ERR1713356_PRJEB13831    2\n",
       "MGYS00001312_ERS1426793_ERR1713346_PRJEB13831    2\n",
       "                                                ..\n",
       "MGYS00001312_ERS1443948_ERR1725972_PRJEB13831    1\n",
       "MGYS00001312_ERS1443952_ERR1725976_PRJEB13831    1\n",
       "MGYS00001312_ERS1443923_ERR1725947_PRJEB13831    1\n",
       "MGYS00001312_ERS1444006_ERR1726030_PRJEB13831    1\n",
       "MGYS00000777_ERS1107853_ERR1352918_PRJEB13232    1\n",
       "Name: count, Length: 1515, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(combined_df_updated['concatenated_ids'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates in the dataset: 99\n"
     ]
    }
   ],
   "source": [
    "new_dataframe = removing_duplicates(combined_df_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1515, 15)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>pipeline_version</th>\n",
       "      <th>instrument_platform</th>\n",
       "      <th>study_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>assembly_run_id</th>\n",
       "      <th>study_name</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>bioproject</th>\n",
       "      <th>centre_name</th>\n",
       "      <th>biomes</th>\n",
       "      <th>pipeline_mapped</th>\n",
       "      <th>initials_run</th>\n",
       "      <th>concatenated_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>MGYA00216506</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 3000</td>\n",
       "      <td>MGYS00001312</td>\n",
       "      <td>ERS1426853</td>\n",
       "      <td>ERR1713406</td>\n",
       "      <td>Global surveillance of infectious diseases and...</td>\n",
       "      <td>179</td>\n",
       "      <td>PRJEB13831</td>\n",
       "      <td>DTU-GE</td>\n",
       "      <td>root:Engineered:Wastewater:Water and sludge</td>\n",
       "      <td>5</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00001312_ERS1426853_ERR1713406_PRJEB13831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>MGYA00085647</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Illumina HiSeq 3000</td>\n",
       "      <td>MGYS00001312</td>\n",
       "      <td>ERS1426853</td>\n",
       "      <td>ERR1713406</td>\n",
       "      <td>Global surveillance of infectious diseases and...</td>\n",
       "      <td>179</td>\n",
       "      <td>PRJEB13831</td>\n",
       "      <td>DTU-GE</td>\n",
       "      <td>root:Engineered:Wastewater:Water and sludge</td>\n",
       "      <td>3</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00001312_ERS1426853_ERR1713406_PRJEB13831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      analysis_id experiment_type  pipeline_version  instrument_platform  \\\n",
       "236  MGYA00216506     metagenomic               4.1  Illumina HiSeq 3000   \n",
       "526  MGYA00085647     metagenomic               3.0  Illumina HiSeq 3000   \n",
       "\n",
       "         study_id   sample_id assembly_run_id  \\\n",
       "236  MGYS00001312  ERS1426853      ERR1713406   \n",
       "526  MGYS00001312  ERS1426853      ERR1713406   \n",
       "\n",
       "                                            study_name  n_samples  bioproject  \\\n",
       "236  Global surveillance of infectious diseases and...        179  PRJEB13831   \n",
       "526  Global surveillance of infectious diseases and...        179  PRJEB13831   \n",
       "\n",
       "    centre_name                                       biomes  pipeline_mapped  \\\n",
       "236      DTU-GE  root:Engineered:Wastewater:Water and sludge                5   \n",
       "526      DTU-GE  root:Engineered:Wastewater:Water and sludge                3   \n",
       "\n",
       "    initials_run                               concatenated_ids  \n",
       "236          ERR  MGYS00001312_ERS1426853_ERR1713406_PRJEB13831  \n",
       "526          ERR  MGYS00001312_ERS1426853_ERR1713406_PRJEB13831  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_updated[combined_df_updated['concatenated_ids']== 'MGYS00001312_ERS1426853_ERR1713406_PRJEB13831']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ERR' 'SRR' 'DRR' 'ERZ']\n"
     ]
    }
   ],
   "source": [
    "print(combined_df_updated.initials_run.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The identifiers ERR, SRR, and DRR are associated with FASTQ files that can be obtained from public sequencing databases.\n",
    "\n",
    "These prefixes represent sequencing run identifiers from three of the main sequencing data archives, which are part of the International Nucleotide Sequence Database Collaboration (INSDC).\n",
    "\n",
    "Here's a brief description:\n",
    "\n",
    "- ERR: European Nucleotide Archive (ENA)\n",
    "- SRR: Sequence Read Archive (SRA) of the National Center for Biotechnology Information (NCBI)\n",
    "- DRR: DNA Data Bank of Japan (DDBJ) Sequence Read Archive\n",
    "\n",
    "These identifiers are used to access sequencing data, including FASTQ files, which contain raw DNA sequences and their quality scores.\n",
    "\n",
    "Users can download the FASTQ files associated with these identifiers using tools like fastq-dump from the SRA Toolkit package or web interfaces of the respective archives.\n",
    "\n",
    "ERZ is not commonly recognized as a standard prefix for identifiers directly associated with FASTQ files in public sequencing databases.\n",
    "\n",
    "It might refer to a specific format or identifier of a particular database or project, but it is not standardized for FASTQ file download like ERR, SRR, and DRR are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prossimi steps\n",
    "\n",
    "1. creare una nuova variabile chiamata \"name_id\" in cui si considerano solo le prime 3 lettere e vengono printate nella nuova colonna. **(DONE)**\n",
    "2. unire study_id, sample_id, assembly_run_id, n_samples e bioproject in un unica variabile stringa e se doppione considerare solo quella con versione piu alta; per fare cio forse conviene utilizzare un dizionario per convertire i float **(DONE)**\n",
    "3. creare una nuova variabile in grado di separare le prime 3 lettere di assembly_run_id **(DONE)**\n",
    "4. creare funzione in grado di scaricare ERR da un sito e altri nominativi da un altro e salvarli in un file txt\n",
    "5. Possiamo creare i file json al di fuori del ciclo for? in questo modo posso creare solo due json e non avere il problema della sovrascrizione.\n",
    "6. adattare la funzione al file finale per scaricare i dati fastq\n",
    "\n",
    "10. scrivere l'analisi in file main.py and functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>pipeline_version</th>\n",
       "      <th>instrument_platform</th>\n",
       "      <th>study_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>assembly_run_id</th>\n",
       "      <th>study_name</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>bioproject</th>\n",
       "      <th>centre_name</th>\n",
       "      <th>biomes</th>\n",
       "      <th>pipeline_mapped</th>\n",
       "      <th>initials_run</th>\n",
       "      <th>concatenated_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MGYA00166416</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488844</td>\n",
       "      <td>ERR2586218</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "      <td>5</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00002383_ERS2488844_ERR2586218_PRJEB26809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MGYA00166417</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488846</td>\n",
       "      <td>ERR2586220</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "      <td>5</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00002383_ERS2488846_ERR2586220_PRJEB26809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MGYA00166418</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488842</td>\n",
       "      <td>ERR2586216</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "      <td>5</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00002383_ERS2488842_ERR2586216_PRJEB26809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MGYA00166419</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488841</td>\n",
       "      <td>ERR2586215</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "      <td>5</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00002383_ERS2488841_ERR2586215_PRJEB26809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MGYA00166420</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488845</td>\n",
       "      <td>ERR2586219</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "      <td>5</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00002383_ERS2488845_ERR2586219_PRJEB26809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    analysis_id experiment_type  pipeline_version  instrument_platform  \\\n",
       "0  MGYA00166416     metagenomic               4.1  Illumina HiSeq 2500   \n",
       "1  MGYA00166417     metagenomic               4.1  Illumina HiSeq 2500   \n",
       "2  MGYA00166418     metagenomic               4.1  Illumina HiSeq 2500   \n",
       "3  MGYA00166419     metagenomic               4.1  Illumina HiSeq 2500   \n",
       "4  MGYA00166420     metagenomic               4.1  Illumina HiSeq 2500   \n",
       "\n",
       "       study_id   sample_id assembly_run_id  \\\n",
       "0  MGYS00002383  ERS2488844      ERR2586218   \n",
       "1  MGYS00002383  ERS2488846      ERR2586220   \n",
       "2  MGYS00002383  ERS2488842      ERR2586216   \n",
       "3  MGYS00002383  ERS2488841      ERR2586215   \n",
       "4  MGYS00002383  ERS2488845      ERR2586219   \n",
       "\n",
       "                                          study_name  n_samples  bioproject  \\\n",
       "0  Antibiotic manufacturing effluent enriches res...          6  PRJEB26809   \n",
       "1  Antibiotic manufacturing effluent enriches res...          6  PRJEB26809   \n",
       "2  Antibiotic manufacturing effluent enriches res...          6  PRJEB26809   \n",
       "3  Antibiotic manufacturing effluent enriches res...          6  PRJEB26809   \n",
       "4  Antibiotic manufacturing effluent enriches res...          6  PRJEB26809   \n",
       "\n",
       "                centre_name                                       biomes  \\\n",
       "0  UNIVERSITY OF GOTHENBURG  root:Engineered:Wastewater:Activated Sludge   \n",
       "1  UNIVERSITY OF GOTHENBURG  root:Engineered:Wastewater:Activated Sludge   \n",
       "2  UNIVERSITY OF GOTHENBURG  root:Engineered:Wastewater:Activated Sludge   \n",
       "3  UNIVERSITY OF GOTHENBURG  root:Engineered:Wastewater:Activated Sludge   \n",
       "4  UNIVERSITY OF GOTHENBURG  root:Engineered:Wastewater:Activated Sludge   \n",
       "\n",
       "   pipeline_mapped initials_run                               concatenated_ids  \n",
       "0                5          ERR  MGYS00002383_ERS2488844_ERR2586218_PRJEB26809  \n",
       "1                5          ERR  MGYS00002383_ERS2488846_ERR2586220_PRJEB26809  \n",
       "2                5          ERR  MGYS00002383_ERS2488842_ERR2586216_PRJEB26809  \n",
       "3                5          ERR  MGYS00002383_ERS2488841_ERR2586215_PRJEB26809  \n",
       "4                5          ERR  MGYS00002383_ERS2488845_ERR2586219_PRJEB26809  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_updated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initials_run\n",
       "ERR    1056\n",
       "ERZ     530\n",
       "SRR      20\n",
       "DRR       8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_updated[\"initials_run\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**European Nucleotide Archive (ENA):**\n",
    "\n",
    "The ENA provides direct access to FASTQ files via FTP or HTTP.\n",
    "\n",
    "You can construct the URL for direct download if you know the run identifier (e.g., ERR, SRR, DRR). The URLs generally follow a standardized format.\n",
    "\n",
    "**NCBI Sequence Read Archive (SRA):**\n",
    "\n",
    "For SRR files, the NCBI does not offer a direct equivalent method to the ENA for downloading via FTP/HTTP without using the SRA Toolkit.\n",
    "\n",
    "However, some third-party tools and services, such as NCBI's EDirect or web services like the Sequence Read Archive (SRA) Explorer, can facilitate the search for direct download URLs when available.\n",
    "\n",
    "**DNA Data Bank of Japan (DDBJ):**\n",
    "\n",
    "Similar to ENA and NCBI, the DDBJ may also offer ways to access data, but the common practice for accessing DRR data is through the SRA Toolkit or web interfaces that facilitate downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>pipeline_version</th>\n",
       "      <th>instrument_platform</th>\n",
       "      <th>study_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>assembly_run_id</th>\n",
       "      <th>study_name</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>bioproject</th>\n",
       "      <th>centre_name</th>\n",
       "      <th>biomes</th>\n",
       "      <th>pipeline_mapped</th>\n",
       "      <th>initials_run</th>\n",
       "      <th>concatenated_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MGYA00166416</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488844</td>\n",
       "      <td>ERR2586218</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "      <td>5</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00002383_ERS2488844_ERR2586218_PRJEB26809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MGYA00166417</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488846</td>\n",
       "      <td>ERR2586220</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "      <td>5</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00002383_ERS2488846_ERR2586220_PRJEB26809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MGYA00166418</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488842</td>\n",
       "      <td>ERR2586216</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "      <td>5</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00002383_ERS2488842_ERR2586216_PRJEB26809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MGYA00166419</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488841</td>\n",
       "      <td>ERR2586215</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "      <td>5</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00002383_ERS2488841_ERR2586215_PRJEB26809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MGYA00166420</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488845</td>\n",
       "      <td>ERR2586219</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "      <td>5</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00002383_ERS2488845_ERR2586219_PRJEB26809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>MGYA00041075</td>\n",
       "      <td>metatranscriptomic</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00000823</td>\n",
       "      <td>ERS1110353</td>\n",
       "      <td>ERR1356740</td>\n",
       "      <td>Studying the presence and selection of antibio...</td>\n",
       "      <td>36</td>\n",
       "      <td>PRJEB13233</td>\n",
       "      <td>EAWAG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "      <td>2</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00000823_ERS1110353_ERR1356740_PRJEB13233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>MGYA00041076</td>\n",
       "      <td>metatranscriptomic</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00000823</td>\n",
       "      <td>ERS1110341</td>\n",
       "      <td>ERR1356716</td>\n",
       "      <td>Studying the presence and selection of antibio...</td>\n",
       "      <td>36</td>\n",
       "      <td>PRJEB13233</td>\n",
       "      <td>EAWAG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "      <td>2</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00000823_ERS1110341_ERR1356716_PRJEB13233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>MGYA00041077</td>\n",
       "      <td>metatranscriptomic</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00000823</td>\n",
       "      <td>ERS1110364</td>\n",
       "      <td>ERR1356762</td>\n",
       "      <td>Studying the presence and selection of antibio...</td>\n",
       "      <td>36</td>\n",
       "      <td>PRJEB13233</td>\n",
       "      <td>EAWAG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "      <td>2</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00000823_ERS1110364_ERR1356762_PRJEB13233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>MGYA00041078</td>\n",
       "      <td>metatranscriptomic</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00000823</td>\n",
       "      <td>ERS1110354</td>\n",
       "      <td>ERR1356742</td>\n",
       "      <td>Studying the presence and selection of antibio...</td>\n",
       "      <td>36</td>\n",
       "      <td>PRJEB13233</td>\n",
       "      <td>EAWAG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "      <td>2</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00000823_ERS1110354_ERR1356742_PRJEB13233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>MGYA00041079</td>\n",
       "      <td>metatranscriptomic</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00000823</td>\n",
       "      <td>ERS1110348</td>\n",
       "      <td>ERR1356731</td>\n",
       "      <td>Studying the presence and selection of antibio...</td>\n",
       "      <td>36</td>\n",
       "      <td>PRJEB13233</td>\n",
       "      <td>EAWAG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "      <td>2</td>\n",
       "      <td>ERR</td>\n",
       "      <td>MGYS00000823_ERS1110348_ERR1356731_PRJEB13233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1056 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       analysis_id     experiment_type  pipeline_version  instrument_platform  \\\n",
       "0     MGYA00166416         metagenomic               4.1  Illumina HiSeq 2500   \n",
       "1     MGYA00166417         metagenomic               4.1  Illumina HiSeq 2500   \n",
       "2     MGYA00166418         metagenomic               4.1  Illumina HiSeq 2500   \n",
       "3     MGYA00166419         metagenomic               4.1  Illumina HiSeq 2500   \n",
       "4     MGYA00166420         metagenomic               4.1  Illumina HiSeq 2500   \n",
       "...            ...                 ...               ...                  ...   \n",
       "1079  MGYA00041075  metatranscriptomic               2.0  Illumina HiSeq 2500   \n",
       "1080  MGYA00041076  metatranscriptomic               2.0  Illumina HiSeq 2500   \n",
       "1081  MGYA00041077  metatranscriptomic               2.0  Illumina HiSeq 2500   \n",
       "1082  MGYA00041078  metatranscriptomic               2.0  Illumina HiSeq 2500   \n",
       "1083  MGYA00041079  metatranscriptomic               2.0  Illumina HiSeq 2500   \n",
       "\n",
       "          study_id   sample_id assembly_run_id  \\\n",
       "0     MGYS00002383  ERS2488844      ERR2586218   \n",
       "1     MGYS00002383  ERS2488846      ERR2586220   \n",
       "2     MGYS00002383  ERS2488842      ERR2586216   \n",
       "3     MGYS00002383  ERS2488841      ERR2586215   \n",
       "4     MGYS00002383  ERS2488845      ERR2586219   \n",
       "...            ...         ...             ...   \n",
       "1079  MGYS00000823  ERS1110353      ERR1356740   \n",
       "1080  MGYS00000823  ERS1110341      ERR1356716   \n",
       "1081  MGYS00000823  ERS1110364      ERR1356762   \n",
       "1082  MGYS00000823  ERS1110354      ERR1356742   \n",
       "1083  MGYS00000823  ERS1110348      ERR1356731   \n",
       "\n",
       "                                             study_name  n_samples  \\\n",
       "0     Antibiotic manufacturing effluent enriches res...          6   \n",
       "1     Antibiotic manufacturing effluent enriches res...          6   \n",
       "2     Antibiotic manufacturing effluent enriches res...          6   \n",
       "3     Antibiotic manufacturing effluent enriches res...          6   \n",
       "4     Antibiotic manufacturing effluent enriches res...          6   \n",
       "...                                                 ...        ...   \n",
       "1079  Studying the presence and selection of antibio...         36   \n",
       "1080  Studying the presence and selection of antibio...         36   \n",
       "1081  Studying the presence and selection of antibio...         36   \n",
       "1082  Studying the presence and selection of antibio...         36   \n",
       "1083  Studying the presence and selection of antibio...         36   \n",
       "\n",
       "      bioproject               centre_name  \\\n",
       "0     PRJEB26809  UNIVERSITY OF GOTHENBURG   \n",
       "1     PRJEB26809  UNIVERSITY OF GOTHENBURG   \n",
       "2     PRJEB26809  UNIVERSITY OF GOTHENBURG   \n",
       "3     PRJEB26809  UNIVERSITY OF GOTHENBURG   \n",
       "4     PRJEB26809  UNIVERSITY OF GOTHENBURG   \n",
       "...          ...                       ...   \n",
       "1079  PRJEB13233                     EAWAG   \n",
       "1080  PRJEB13233                     EAWAG   \n",
       "1081  PRJEB13233                     EAWAG   \n",
       "1082  PRJEB13233                     EAWAG   \n",
       "1083  PRJEB13233                     EAWAG   \n",
       "\n",
       "                                           biomes  pipeline_mapped  \\\n",
       "0     root:Engineered:Wastewater:Activated Sludge                5   \n",
       "1     root:Engineered:Wastewater:Activated Sludge                5   \n",
       "2     root:Engineered:Wastewater:Activated Sludge                5   \n",
       "3     root:Engineered:Wastewater:Activated Sludge                5   \n",
       "4     root:Engineered:Wastewater:Activated Sludge                5   \n",
       "...                                           ...              ...   \n",
       "1079  root:Engineered:Wastewater:Activated Sludge                2   \n",
       "1080  root:Engineered:Wastewater:Activated Sludge                2   \n",
       "1081  root:Engineered:Wastewater:Activated Sludge                2   \n",
       "1082  root:Engineered:Wastewater:Activated Sludge                2   \n",
       "1083  root:Engineered:Wastewater:Activated Sludge                2   \n",
       "\n",
       "     initials_run                               concatenated_ids  \n",
       "0             ERR  MGYS00002383_ERS2488844_ERR2586218_PRJEB26809  \n",
       "1             ERR  MGYS00002383_ERS2488846_ERR2586220_PRJEB26809  \n",
       "2             ERR  MGYS00002383_ERS2488842_ERR2586216_PRJEB26809  \n",
       "3             ERR  MGYS00002383_ERS2488841_ERR2586215_PRJEB26809  \n",
       "4             ERR  MGYS00002383_ERS2488845_ERR2586219_PRJEB26809  \n",
       "...           ...                                            ...  \n",
       "1079          ERR  MGYS00000823_ERS1110353_ERR1356740_PRJEB13233  \n",
       "1080          ERR  MGYS00000823_ERS1110341_ERR1356716_PRJEB13233  \n",
       "1081          ERR  MGYS00000823_ERS1110364_ERR1356762_PRJEB13233  \n",
       "1082          ERR  MGYS00000823_ERS1110354_ERR1356742_PRJEB13233  \n",
       "1083          ERR  MGYS00000823_ERS1110348_ERR1356731_PRJEB13233  \n",
       "\n",
       "[1056 rows x 15 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_updated[combined_df_updated['initials_run']== 'ERR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_ERR = combined_df_updated[combined_df_updated['initials_run']== 'ERR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1056, 15)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_ERR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/marcor/Desktop/Marco/projects/proj003_mgnify/Retrieve_info_MGnifyAPI/notebooks/test_version3.ipynb Cell 31\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/marcor/Desktop/Marco/projects/proj003_mgnify/Retrieve_info_MGnifyAPI/notebooks/test_version3.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m combined_df_ERR\u001b[39m.\u001b[39;49massembly_run_id\u001b[39m.\u001b[39;49munique()\u001b[39m.\u001b[39;49mcount()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'count'"
     ]
    }
   ],
   "source": [
    "combined_df_ERR.assembly_run_id.unique().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ftplib import FTP\n",
    "server_address = 'ftp.sra.ebi.ac.uk'\n",
    "\n",
    "\n",
    "\n",
    "def download_files_from_list(server, input_ids_file, local_directory, remote_directory = '/vol1/fastq/'):\n",
    "    try:\n",
    "        ftp = FTP(server)\n",
    "        ftp.login()\n",
    "\n",
    "        with open(input_ids_file, 'r') as id_file:\n",
    "            ids = id_file.readlines()\n",
    "\n",
    "            for id_name in ids:\n",
    "                id_name = id_name.strip()\n",
    "                folder_name = id_name[:6]\n",
    "\n",
    "                remote_path = f\"{remote_directory}/{folder_name}/{id_name}/\"\n",
    "                local_path = f\"{local_directory}/{folder_name}/{id_name}/\"\n",
    "\n",
    "                os.makedirs(local_path, exist_ok=True)\n",
    "\n",
    "                ftp.cwd(remote_path)\n",
    "\n",
    "                files_to_download = ftp.nlst()\n",
    "\n",
    "                for file in files_to_download:\n",
    "                    with open(os.path.join(local_path, file), 'wb') as local_file:\n",
    "                        # wb = write - binary \n",
    "                        ftp.retrbinary('RETR ' + file, local_file.write)\n",
    "                        # retrbinary = download files in binary format (retrieve binary)\n",
    "                    print(f\"File {file} successfully downloaded in {local_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        ftp.quit()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def download_fastq_files(ids, output_directory):\n",
    "    \"\"\"\n",
    "    Scarica i file FASTQ per una lista di identificativi SRA utilizzando lo SRA Toolkit, senza un ciclo for interno alla funzione.\n",
    "\n",
    "    Args:\n",
    "        ids (list): Una lista di stringhe contenenti gli identificativi SRA da scaricare.\n",
    "        output_directory (str): Il percorso della directory dove salvare i file FASTQ.\n",
    "    \"\"\"\n",
    "    # Configura lo SRA Toolkit per ignorare la verifica dei certificati SSL (Attenzione: aumenta il rischio di sicurezza)\n",
    "    os.environ['VDB_CONFIG'] = 'kfg/tls/disabled=true'\n",
    "\n",
    "    # Imposta il comando per prefetch e fasterq-dump utilizzando tutti gli ID contemporaneamente\n",
    "    prefetch_cmd = ['prefetch'] + ids\n",
    "    fasterq_dump_cmd = ['fasterq-dump', '--split-files', '--outdir', output_directory, '-e', '8'] + ids\n",
    "\n",
    "    # Esegue prefetch per tutti gli ID forniti\n",
    "    subprocess.run(prefetch_cmd)\n",
    "\n",
    "    # Esegue fasterq-dump per convertire tutti i file SRA scaricati in FASTQ e salvarli nella directory di output\n",
    "    subprocess.run(fasterq_dump_cmd)\n",
    "\n",
    "    print(\"Download completato.\")\n",
    "\n",
    "# Esempio di utilizzo della funzione\n",
    "ids = ['SRR2107182', 'SRR2107184'] \n",
    "output_directory = '../outputs'\n",
    "\n",
    "download_fastq_files(ids, output_directory)\n",
    "\n",
    "# Ricorda di rimuovere o commentare la linea che configura la variabile d'ambiente dopo l'uso per evitare di lasciare il sistema in uno stato meno sic\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imputation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
