{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MGnify notebook: retrieve info from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_studies_and_analyses_summary(biome_name, experiment_type):\n",
    "    # set the urls\n",
    "    urls = {\"studies\": \"https://www.ebi.ac.uk/metagenomics/api/v1/studies\", \"analyses\": \"https://www.ebi.ac.uk/metagenomics/api/v1/analyses\"}\n",
    "    # common parts\n",
    "    common_params = {\"biome_name\": biome_name}\n",
    "    all_data = {\"studies\": [], \"analyses\": []}\n",
    "\n",
    "    # connection request\n",
    "    for key, url in urls.items():\n",
    "        params = common_params.copy()\n",
    "        if key == \"analyses\":\n",
    "            params.update({\n",
    "                \"lineage\": biome_name,\n",
    "                \"experiment_type\": experiment_type\n",
    "            })\n",
    "        page = 1\n",
    "        while True:\n",
    "            try:\n",
    "                print(f\"Retrieving data for page {page}...\")\n",
    "                params[\"page\"] = page\n",
    "                response = requests.get(url, params=params)\n",
    "                response.raise_for_status()  # errors codes HTTP\n",
    "                \n",
    "                data = response.json()[\"data\"]\n",
    "                page_info = response.json()[\"meta\"][\"pagination\"]\n",
    "                all_data[key].extend(data)\n",
    "                print(f\"Page {page} retrieved successfully. Total pages: {page_info['pages']}\")\n",
    "\n",
    "                if page >= page_info[\"pages\"]:\n",
    "                    break\n",
    "                page += 1\n",
    "            except requests.exceptions.HTTPError as http_err:\n",
    "                print(f\"HTTP error occurred: {http_err} - Status code: {response.status_code}\")\n",
    "                break\n",
    "            except Exception as err:\n",
    "                print(f\"An error occurred: {err}\")\n",
    "                break\n",
    "    \n",
    "    # building dataframes\n",
    "    studies_columns = ['study_id', 'study_name', 'n_samples', 'bioproject', 'centre_name', 'biomes']\n",
    "    studies_data = []\n",
    "    for item in all_data['studies']:\n",
    "        studies_data.append({\n",
    "            'study_id': item['id'],\n",
    "            'study_name': item['attributes'].get('study-name', ''),\n",
    "            'n_samples': item['attributes'].get('samples-count', 0),\n",
    "            'bioproject': item['attributes'].get('bioproject', ''),\n",
    "            'centre_name': item['attributes'].get('centre-name', ''),\n",
    "            'biomes': \", \".join([biome['id'] for biome in item['relationships']['biomes']['data']])\n",
    "            })\n",
    "    df_studies = pd.DataFrame(studies_data, columns=studies_columns)\n",
    "\n",
    "    analyses_columns = ['analysis_id', 'experiment_type', 'pipeline_version', 'instrument_platform', 'study_id', 'sample_id', 'assembly_run_id']\n",
    "    analyses_data = []\n",
    "    for item in all_data['analyses']:\n",
    "        analyses_data.append({\n",
    "            'analysis_id': item['id'],\n",
    "            'experiment_type': item['attributes'].get('experiment-type', ''),\n",
    "            'pipeline_version': item['attributes'].get('pipeline-version', ''),\n",
    "            'instrument_platform': item['attributes'].get('instrument-model', ''),\n",
    "            'study_id': item['relationships']['study']['data'].get('id', '') if item['relationships'].get('study') else '',\n",
    "            'sample_id': item['relationships']['sample']['data'].get('id', '') if item['relationships'].get('sample') else '',\n",
    "            'assembly_run_id': item['relationships'].get('assembly', {}).get('data', {}).get('id', '') if item['attributes'].get('experiment-type') == 'assembly' else item['relationships'].get('run', {}).get('data', {}).get('id', '')\n",
    "            })\n",
    "    df_analyses = pd.DataFrame(analyses_data, columns=analyses_columns)\n",
    "\n",
    "    # merging dataframe and return it\n",
    "    df_summary = pd.merge(df_analyses, df_studies, on='study_id', how='left')\n",
    "    \n",
    "    return df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_biomes_and_save(output_dir):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        output_dir (_type_): _description_\n",
    "    \"\"\"\n",
    "    url = \"https://www.ebi.ac.uk/metagenomics/api/v1/biomes\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        biomes_data = response.json()\n",
    "        biomes_list = [biome['id'] for biome in biomes_data['data']]\n",
    "        \n",
    "        with open(os.path.join(output_dir,\"mgnify_biomes_list.txt\"), 'w') as file:\n",
    "            for biome_name in biomes_list:\n",
    "                file.write(f\"{biome_name}\\n\")\n",
    "                \n",
    "        print(f\"Biomes list saved.\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Failed to retrieve biomes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_studies_and_analyses_summary(biome_name, experiment_type, output_dir = '../outputs'):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        biome_name (_type_): _description_\n",
    "        experiment_type (_type_): _description_\n",
    "        output_dir (str, optional): _description_. Defaults to '../outputs'.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # set the urls\n",
    "    urls = {\"studies\": \"https://www.ebi.ac.uk/metagenomics/api/v1/studies\", \"analyses\": \"https://www.ebi.ac.uk/metagenomics/api/v1/analyses\"}\n",
    "    # common parts\n",
    "    common_params = {\"biome_name\": biome_name}\n",
    "    all_data = {\"studies\": [], \"analyses\": []}\n",
    "\n",
    "    # connection request\n",
    "    for key, url in urls.items():\n",
    "        if key == \"studies\" and all_data[\"studies\"]:\n",
    "            continue\n",
    "\n",
    "        params = common_params.copy()\n",
    "        if key == \"analyses\":\n",
    "            params.update({\n",
    "                \"lineage\": biome_name,\n",
    "                \"experiment_type\": experiment_type\n",
    "            })\n",
    "\n",
    "        page = 1\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                print(f\"Retrieving data for page {page}...\")\n",
    "                params[\"page\"] = page\n",
    "                response = requests.get(url, params=params)\n",
    "                response.raise_for_status()  # errors codes HTTP\n",
    "                \n",
    "                data = response.json()[\"data\"]\n",
    "                page_info = response.json()[\"meta\"][\"pagination\"]\n",
    "                all_data[key].extend(data)\n",
    "                print(f\"Page {page} retrieved successfully. Total pages: {page_info['pages']}\")\n",
    "\n",
    "                if page >= page_info[\"pages\"]:\n",
    "                    break\n",
    "                page += 1\n",
    "            except requests.exceptions.HTTPError as http_err:\n",
    "                print(f\"HTTP error occurred: {http_err} - Status code: {response.status_code}\")\n",
    "                break\n",
    "            except Exception as err:\n",
    "                print(f\"An error occurred: {err}\")\n",
    "                break\n",
    "        \n",
    "        # save json files\n",
    "        if key == \"studies\":\n",
    "            output_file_path = os.path.join(output_dir, \"mgnify_studies.json\")\n",
    "        else:\n",
    "            output_file_path = os.path.join(output_dir, f\"mgnify_analyses_{experiment_type}.json\")\n",
    "        \n",
    "        with open(output_file_path, \"w\") as outfile:\n",
    "            json.dump(all_data[key], outfile)\n",
    "        print(f\"{key.capitalize()} data for {experiment_type} saved to {output_file_path}\")\n",
    "\n",
    "\n",
    "    # building dataframes\n",
    "    studies_columns = ['study_id', 'study_name', 'n_samples', 'bioproject', 'centre_name', 'biomes']\n",
    "    studies_data = []\n",
    "    for item in all_data['studies']:\n",
    "        studies_data.append({\n",
    "            'study_id': item['id'],\n",
    "            'study_name': item['attributes'].get('study-name', ''),\n",
    "            'n_samples': item['attributes'].get('samples-count', 0),\n",
    "            'bioproject': item['attributes'].get('bioproject', ''),\n",
    "            'centre_name': item['attributes'].get('centre-name', ''),\n",
    "            'biomes': \", \".join([biome['id'] for biome in item['relationships']['biomes']['data']])\n",
    "            })\n",
    "    df_studies = pd.DataFrame(studies_data, columns=studies_columns)\n",
    "\n",
    "    analyses_columns = ['analysis_id', 'experiment_type', 'pipeline_version', 'instrument_platform', 'study_id', 'sample_id', 'assembly_run_id']\n",
    "    analyses_data = []\n",
    "    for item in all_data['analyses']:\n",
    "        analyses_data.append({\n",
    "            'analysis_id': item['id'],\n",
    "            'experiment_type': item['attributes'].get('experiment-type', ''),\n",
    "            'pipeline_version': item['attributes'].get('pipeline-version', ''),\n",
    "            'instrument_platform': item['attributes'].get('instrument-model', ''),\n",
    "            'study_id': item['relationships']['study']['data'].get('id', '') if item['relationships'].get('study') else '',\n",
    "            'sample_id': item['relationships']['sample']['data'].get('id', '') if item['relationships'].get('sample') else '',\n",
    "            'assembly_run_id': item['relationships'].get('assembly', {}).get('data', {}).get('id', '') if item['attributes'].get('experiment-type') == 'assembly' else item['relationships'].get('run', {}).get('data', {}).get('id', '')\n",
    "            })\n",
    "    df_analyses = pd.DataFrame(analyses_data, columns=analyses_columns)\n",
    "\n",
    "    # merging dataframe and return it\n",
    "    df_summary = pd.merge(df_analyses, df_studies, on='study_id', how='left')\n",
    "    \n",
    "    return df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING STEP 1: fetch_biomes_and_save\n",
      "Biomes list saved.\n",
      "STARTING STEP 2: get_studies_and_analyses_summary\n",
      "Processing experiment type: metagenomic\n",
      "Retrieving data for page 1...\n",
      "Page 1 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 2...\n",
      "Page 2 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 3...\n",
      "Page 3 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 4...\n",
      "Page 4 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 5...\n",
      "Page 5 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 6...\n",
      "Page 6 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 7...\n",
      "Page 7 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 8...\n",
      "Page 8 retrieved successfully. Total pages: 8\n",
      "Studies data for metagenomic saved to ../outputs/mgnify_studies.json\n",
      "Retrieving data for page 1...\n",
      "Page 1 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 2...\n",
      "Page 2 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 3...\n",
      "Page 3 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 4...\n",
      "Page 4 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 5...\n",
      "Page 5 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 6...\n",
      "Page 6 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 7...\n",
      "Page 7 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 8...\n",
      "Page 8 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 9...\n",
      "Page 9 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 10...\n",
      "Page 10 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 11...\n",
      "Page 11 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 12...\n",
      "Page 12 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 13...\n",
      "Page 13 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 14...\n",
      "Page 14 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 15...\n",
      "Page 15 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 16...\n",
      "Page 16 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 17...\n",
      "Page 17 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 18...\n",
      "Page 18 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 19...\n",
      "Page 19 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 20...\n",
      "Page 20 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 21...\n",
      "Page 21 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 22...\n",
      "Page 22 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 23...\n",
      "Page 23 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 24...\n",
      "Page 24 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 25...\n",
      "Page 25 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 26...\n",
      "Page 26 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 27...\n",
      "Page 27 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 28...\n",
      "Page 28 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 29...\n",
      "Page 29 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 30...\n",
      "Page 30 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 31...\n",
      "Page 31 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 32...\n",
      "Page 32 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 33...\n",
      "Page 33 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 34...\n",
      "Page 34 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 35...\n",
      "Page 35 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 36...\n",
      "Page 36 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 37...\n",
      "Page 37 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 38...\n",
      "Page 38 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 39...\n",
      "Page 39 retrieved successfully. Total pages: 40\n",
      "Retrieving data for page 40...\n",
      "Page 40 retrieved successfully. Total pages: 40\n",
      "Analyses data for metagenomic saved to ../outputs/mgnify_analyses_metagenomic.json\n",
      "Processing experiment type: metatranscriptomic\n",
      "Retrieving data for page 1...\n",
      "Page 1 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 2...\n",
      "Page 2 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 3...\n",
      "Page 3 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 4...\n",
      "Page 4 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 5...\n",
      "Page 5 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 6...\n",
      "Page 6 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 7...\n",
      "Page 7 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 8...\n",
      "Page 8 retrieved successfully. Total pages: 8\n",
      "Studies data for metatranscriptomic saved to ../outputs/mgnify_studies.json\n",
      "Retrieving data for page 1...\n",
      "Page 1 retrieved successfully. Total pages: 4\n",
      "Retrieving data for page 2...\n",
      "Page 2 retrieved successfully. Total pages: 4\n",
      "Retrieving data for page 3...\n",
      "Page 3 retrieved successfully. Total pages: 4\n",
      "Retrieving data for page 4...\n",
      "Page 4 retrieved successfully. Total pages: 4\n",
      "Analyses data for metatranscriptomic saved to ../outputs/mgnify_analyses_metatranscriptomic.json\n",
      "Processing experiment type: assembly\n",
      "Retrieving data for page 1...\n",
      "Page 1 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 2...\n",
      "Page 2 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 3...\n",
      "Page 3 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 4...\n",
      "Page 4 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 5...\n",
      "Page 5 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 6...\n",
      "Page 6 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 7...\n",
      "Page 7 retrieved successfully. Total pages: 8\n",
      "Retrieving data for page 8...\n",
      "Page 8 retrieved successfully. Total pages: 8\n",
      "Studies data for assembly saved to ../outputs/mgnify_studies.json\n",
      "Retrieving data for page 1...\n",
      "Page 1 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 2...\n",
      "Page 2 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 3...\n",
      "Page 3 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 4...\n",
      "Page 4 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 5...\n",
      "Page 5 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 6...\n",
      "Page 6 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 7...\n",
      "Page 7 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 8...\n",
      "Page 8 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 9...\n",
      "Page 9 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 10...\n",
      "Page 10 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 11...\n",
      "Page 11 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 12...\n",
      "Page 12 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 13...\n",
      "Page 13 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 14...\n",
      "Page 14 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 15...\n",
      "Page 15 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 16...\n",
      "Page 16 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 17...\n",
      "Page 17 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 18...\n",
      "Page 18 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 19...\n",
      "Page 19 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 20...\n",
      "Page 20 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 21...\n",
      "Page 21 retrieved successfully. Total pages: 22\n",
      "Retrieving data for page 22...\n",
      "Page 22 retrieved successfully. Total pages: 22\n",
      "Analyses data for assembly saved to ../outputs/mgnify_analyses_assembly.json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # setting the variables \n",
    "    biome = \"root:Engineered:Wastewater\"\n",
    "    biome_lower = biome.replace(\":\", \"_\").lower()\n",
    "    experiments = (\"metagenomic\",\"metatranscriptomic\",\"assembly\")\n",
    "    output_path = '../outputs/'\n",
    "    df_summary_dict = {}\n",
    "\n",
    "    print('STARTING STEP 1: fetch_biomes_and_save')\n",
    "    fetch_biomes_and_save(output_dir= output_path)\n",
    "\n",
    "    print('STARTING STEP 2: get_studies_and_analyses_summary')\n",
    "    for exp in experiments:\n",
    "        print(f\"Processing experiment type: {exp}\")\n",
    "        df_summary = get_studies_and_analyses_summary(biome_name=biome, experiment_type=exp)\n",
    "        df_summary_dict[exp] = df_summary  # Aggiungi il DataFrame al dizionario\n",
    "\n",
    "        # save the CSV file\n",
    "        df_summary.to_csv(os.path.join(output_path, f\"{biome_lower}_{exp}_summary.csv\"), index=False)\n",
    "        combined_df = pd.concat(df_summary_dict.values(), axis=0)\n",
    "        combined_df.to_csv(os.path.join(output_path, 'combined_dataframe.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(os.path.join(output_path, 'combined_dataframe.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>pipeline_version</th>\n",
       "      <th>instrument_platform</th>\n",
       "      <th>study_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>assembly_run_id</th>\n",
       "      <th>study_name</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>bioproject</th>\n",
       "      <th>centre_name</th>\n",
       "      <th>biomes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MGYA00166416</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488844</td>\n",
       "      <td>ERR2586218</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MGYA00166417</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488846</td>\n",
       "      <td>ERR2586220</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MGYA00166418</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488842</td>\n",
       "      <td>ERR2586216</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    analysis_id experiment_type pipeline_version  instrument_platform  \\\n",
       "0  MGYA00166416     metagenomic              4.1  Illumina HiSeq 2500   \n",
       "1  MGYA00166417     metagenomic              4.1  Illumina HiSeq 2500   \n",
       "2  MGYA00166418     metagenomic              4.1  Illumina HiSeq 2500   \n",
       "\n",
       "       study_id   sample_id assembly_run_id  \\\n",
       "0  MGYS00002383  ERS2488844      ERR2586218   \n",
       "1  MGYS00002383  ERS2488846      ERR2586220   \n",
       "2  MGYS00002383  ERS2488842      ERR2586216   \n",
       "\n",
       "                                          study_name  n_samples  bioproject  \\\n",
       "0  Antibiotic manufacturing effluent enriches res...          6  PRJEB26809   \n",
       "1  Antibiotic manufacturing effluent enriches res...          6  PRJEB26809   \n",
       "2  Antibiotic manufacturing effluent enriches res...          6  PRJEB26809   \n",
       "\n",
       "                centre_name                                       biomes  \n",
       "0  UNIVERSITY OF GOTHENBURG  root:Engineered:Wastewater:Activated Sludge  \n",
       "1  UNIVERSITY OF GOTHENBURG  root:Engineered:Wastewater:Activated Sludge  \n",
       "2  UNIVERSITY OF GOTHENBURG  root:Engineered:Wastewater:Activated Sludge  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "analysis_id             object\n",
       "experiment_type         object\n",
       "pipeline_version       float64\n",
       "instrument_platform     object\n",
       "study_id                object\n",
       "sample_id               object\n",
       "assembly_run_id         object\n",
       "study_name              object\n",
       "n_samples                int64\n",
       "bioproject              object\n",
       "centre_name             object\n",
       "biomes                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_dataset(dataset):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        dataset (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # count number of unique 'study_id'\n",
    "    print(f\"\\nTotal number of unique studies: {dataset[\"study_id\"].nunique()}\")\n",
    "\n",
    "    print(f\"\\nNumber of unique assembly_run_id per study_id:{combined_df.groupby(\"study_id\")[\"assembly_run_id\"].nunique()}\")\n",
    "\n",
    "    # missing values\n",
    "    print(f\"\\nMissing values per variable:{dataset.isnull().sum()}\")\n",
    "    \n",
    "    print(f\"\\nNumber of samples per biome:{combined_df.groupby('biomes')['n_samples'].median().reset_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of unique studies: 117\n",
      "\n",
      "Number of unique assembly_run_id per study_id:study_id\n",
      "MGYS00000423      1\n",
      "MGYS00000425      1\n",
      "MGYS00000555      1\n",
      "MGYS00000597     16\n",
      "MGYS00000606      1\n",
      "               ... \n",
      "MGYS00005614      8\n",
      "MGYS00005769     11\n",
      "MGYS00005802      6\n",
      "MGYS00005846    110\n",
      "MGYS00006570    152\n",
      "Name: assembly_run_id, Length: 117, dtype: int64\n",
      "\n",
      "Missing values per variable:analysis_id            0\n",
      "experiment_type        0\n",
      "pipeline_version       0\n",
      "instrument_platform    0\n",
      "study_id               0\n",
      "sample_id              0\n",
      "assembly_run_id        0\n",
      "study_name             0\n",
      "n_samples              0\n",
      "bioproject             0\n",
      "centre_name            0\n",
      "biomes                 0\n",
      "dtype: int64\n",
      "\n",
      "Number of samples per biome:                                              biomes  n_samples\n",
      "0                         root:Engineered:Wastewater       81.0\n",
      "1        root:Engineered:Wastewater:Activated Sludge       12.0\n",
      "2  root:Engineered:Wastewater:Activated Sludge, r...       70.0\n",
      "3   root:Engineered:Wastewater:Industrial wastewater       30.0\n",
      "4  root:Engineered:Wastewater:Industrial wastewat...        1.0\n",
      "5  root:Engineered:Wastewater:Industrial wastewat...       14.0\n",
      "6  root:Engineered:Wastewater:Nutrient removal:Bi...        6.0\n",
      "7  root:Engineered:Wastewater:Nutrient removal:Di...        6.0\n",
      "8  root:Engineered:Wastewater:Nutrient removal:Ni...        1.0\n",
      "9        root:Engineered:Wastewater:Water and sludge      179.0\n"
     ]
    }
   ],
   "source": [
    "explore_dataset(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1614, 12)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['metagenomic', 'metatranscriptomic', 'assembly'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.experiment_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribuzione di experiment_type:\n",
      "experiment_type\n",
      "metagenomic           985\n",
      "assembly              530\n",
      "metatranscriptomic     99\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribuzione di biomes:\n",
      "biomes\n",
      "root:Engineered:Wastewater:Water and sludge                                                      708\n",
      "root:Engineered:Wastewater                                                                       497\n",
      "root:Engineered:Wastewater:Activated Sludge                                                      225\n",
      "root:Engineered:Wastewater:Activated Sludge, root:Engineered:Wastewater:Industrial wastewater     70\n",
      "root:Engineered:Wastewater:Industrial wastewater                                                  67\n",
      "root:Engineered:Wastewater:Industrial wastewater:Petrochemical                                    24\n",
      "root:Engineered:Wastewater:Nutrient removal:Dissolved organics (anaerobic)                        12\n",
      "root:Engineered:Wastewater:Nutrient removal:Biological phosphorus removal:Activated sludge         8\n",
      "root:Engineered:Wastewater:Industrial wastewater:Agricultural wastewater                           2\n",
      "root:Engineered:Wastewater:Nutrient removal:Nitrogen removal                                       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4. Esplorare la distribuzione di 'experiment_type' e 'biomes'\n",
    "experiment_type_counts = combined_df[\"experiment_type\"].value_counts()\n",
    "biomes_counts = combined_df[\"biomes\"].value_counts()\n",
    "print(\"\\nDistribuzione di experiment_type:\")\n",
    "print(experiment_type_counts)\n",
    "print(\"\\nDistribuzione di biomes:\")\n",
    "print(biomes_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any missing data in the dataframe? no\n"
     ]
    }
   ],
   "source": [
    "# missing data\n",
    "any_missing_data = combined_df.isnull().values.any()\n",
    "\n",
    "print(f\"Are there any missing data in the dataframe? {'yes' if any_missing_data else 'no'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>pipeline_version</th>\n",
       "      <th>instrument_platform</th>\n",
       "      <th>study_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>assembly_run_id</th>\n",
       "      <th>study_name</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>bioproject</th>\n",
       "      <th>centre_name</th>\n",
       "      <th>biomes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MGYA00166416</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488844</td>\n",
       "      <td>ERR2586218</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MGYA00166417</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488846</td>\n",
       "      <td>ERR2586220</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MGYA00166418</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488842</td>\n",
       "      <td>ERR2586216</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MGYA00166419</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488841</td>\n",
       "      <td>ERR2586215</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MGYA00166420</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>MGYS00002383</td>\n",
       "      <td>ERS2488845</td>\n",
       "      <td>ERR2586219</td>\n",
       "      <td>Antibiotic manufacturing effluent enriches res...</td>\n",
       "      <td>6</td>\n",
       "      <td>PRJEB26809</td>\n",
       "      <td>UNIVERSITY OF GOTHENBURG</td>\n",
       "      <td>root:Engineered:Wastewater:Activated Sludge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    analysis_id experiment_type  pipeline_version  instrument_platform  \\\n",
       "0  MGYA00166416     metagenomic               4.1  Illumina HiSeq 2500   \n",
       "1  MGYA00166417     metagenomic               4.1  Illumina HiSeq 2500   \n",
       "2  MGYA00166418     metagenomic               4.1  Illumina HiSeq 2500   \n",
       "3  MGYA00166419     metagenomic               4.1  Illumina HiSeq 2500   \n",
       "4  MGYA00166420     metagenomic               4.1  Illumina HiSeq 2500   \n",
       "\n",
       "       study_id   sample_id assembly_run_id  \\\n",
       "0  MGYS00002383  ERS2488844      ERR2586218   \n",
       "1  MGYS00002383  ERS2488846      ERR2586220   \n",
       "2  MGYS00002383  ERS2488842      ERR2586216   \n",
       "3  MGYS00002383  ERS2488841      ERR2586215   \n",
       "4  MGYS00002383  ERS2488845      ERR2586219   \n",
       "\n",
       "                                          study_name  n_samples  bioproject  \\\n",
       "0  Antibiotic manufacturing effluent enriches res...          6  PRJEB26809   \n",
       "1  Antibiotic manufacturing effluent enriches res...          6  PRJEB26809   \n",
       "2  Antibiotic manufacturing effluent enriches res...          6  PRJEB26809   \n",
       "3  Antibiotic manufacturing effluent enriches res...          6  PRJEB26809   \n",
       "4  Antibiotic manufacturing effluent enriches res...          6  PRJEB26809   \n",
       "\n",
       "                centre_name                                       biomes  \n",
       "0  UNIVERSITY OF GOTHENBURG  root:Engineered:Wastewater:Activated Sludge  \n",
       "1  UNIVERSITY OF GOTHENBURG  root:Engineered:Wastewater:Activated Sludge  \n",
       "2  UNIVERSITY OF GOTHENBURG  root:Engineered:Wastewater:Activated Sludge  \n",
       "3  UNIVERSITY OF GOTHENBURG  root:Engineered:Wastewater:Activated Sludge  \n",
       "4  UNIVERSITY OF GOTHENBURG  root:Engineered:Wastewater:Activated Sludge  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['metagenomic', 'metatranscriptomic', 'assembly'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.experiment_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_type\n",
      "metagenomic           985\n",
      "assembly              530\n",
      "metatranscriptomic     99\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "experiment_type_counts = combined_df[\"experiment_type\"].value_counts()\n",
    "print(experiment_type_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "analysis_id             object\n",
       "experiment_type         object\n",
       "pipeline_version       float64\n",
       "instrument_platform     object\n",
       "study_id                object\n",
       "sample_id               object\n",
       "assembly_run_id         object\n",
       "study_name              object\n",
       "n_samples                int64\n",
       "bioproject              object\n",
       "centre_name             object\n",
       "biomes                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1614, 12)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n",
      "162\n",
      "197\n"
     ]
    }
   ],
   "source": [
    "### do we have different pipeline versions considering different IDs?\n",
    "\n",
    "analysis_versions = combined_df.groupby('analysis_id')['pipeline_version'].nunique()\n",
    "study_versions = combined_df.groupby('study_id')['pipeline_version'].nunique()\n",
    "sample_versions = combined_df.groupby('sample_id')['pipeline_version'].nunique()\n",
    "run_versions = combined_df.groupby('assembly_run_id')['pipeline_version'].nunique()\n",
    "\n",
    "multiple_versions_ana = analysis_versions[analysis_versions > 1]\n",
    "multiple_versions_stu = study_versions[study_versions > 1]\n",
    "multiple_versions_sam = sample_versions[sample_versions > 1]\n",
    "multiple_versions_run = run_versions[run_versions > 1]\n",
    "\n",
    "print(len(multiple_versions_ana))\n",
    "print(len(multiple_versions_stu))\n",
    "print(len(multiple_versions_sam))\n",
    "print(len(multiple_versions_run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>pipeline_version</th>\n",
       "      <th>instrument_platform</th>\n",
       "      <th>study_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>assembly_run_id</th>\n",
       "      <th>study_name</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>bioproject</th>\n",
       "      <th>centre_name</th>\n",
       "      <th>biomes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>MGYA00216627</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Illumina HiSeq 3000</td>\n",
       "      <td>MGYS00001312</td>\n",
       "      <td>ERS1426778</td>\n",
       "      <td>ERR1713331</td>\n",
       "      <td>Global surveillance of infectious diseases and...</td>\n",
       "      <td>179</td>\n",
       "      <td>PRJEB13831</td>\n",
       "      <td>DTU-GE</td>\n",
       "      <td>root:Engineered:Wastewater:Water and sludge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>MGYA00085654</td>\n",
       "      <td>metagenomic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Illumina HiSeq 3000</td>\n",
       "      <td>MGYS00001312</td>\n",
       "      <td>ERS1426778</td>\n",
       "      <td>ERR1713331</td>\n",
       "      <td>Global surveillance of infectious diseases and...</td>\n",
       "      <td>179</td>\n",
       "      <td>PRJEB13831</td>\n",
       "      <td>DTU-GE</td>\n",
       "      <td>root:Engineered:Wastewater:Water and sludge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      analysis_id experiment_type  pipeline_version  instrument_platform  \\\n",
       "357  MGYA00216627     metagenomic               4.1  Illumina HiSeq 3000   \n",
       "533  MGYA00085654     metagenomic               3.0  Illumina HiSeq 3000   \n",
       "\n",
       "         study_id   sample_id assembly_run_id  \\\n",
       "357  MGYS00001312  ERS1426778      ERR1713331   \n",
       "533  MGYS00001312  ERS1426778      ERR1713331   \n",
       "\n",
       "                                            study_name  n_samples  bioproject  \\\n",
       "357  Global surveillance of infectious diseases and...        179  PRJEB13831   \n",
       "533  Global surveillance of infectious diseases and...        179  PRJEB13831   \n",
       "\n",
       "    centre_name                                       biomes  \n",
       "357      DTU-GE  root:Engineered:Wastewater:Water and sludge  \n",
       "533      DTU-GE  root:Engineered:Wastewater:Water and sludge  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[combined_df['assembly_run_id'] == 'ERR1713331']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prossimi steps\n",
    "\n",
    "1. creare una nuova variabile chiamata \"name_id\" in cui si considerano solo le prime 3 lettere e vengono printate nella nuova colonna.\n",
    "2. unire study_id, sample_id, assembly_run_id, n_samples e bioproject in un unica variabile stringa e se doppione considerare solo quella con versione piu alta; per fare cio forse conviene utilizzare un dizionario per convertire i float \n",
    "3. creare una nuova variabile in grado di separare le prime 3 lettere di assembly_run_id\n",
    "4. creare funzione in grado di scaricare ERR da un sito e altri nominativi da un altro e salvarli in un file txt\n",
    "5. Possiamo creare i file json al di fuori del ciclo for? in questo modo posso creare solo due json e non avere il problema della sovrascrizione.\n",
    "6. adattare la funzione al file finale per scaricare i dati fastq\n",
    "\n",
    "10. scrivere l'analisi in file main.py and functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imputation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
